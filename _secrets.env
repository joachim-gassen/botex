# Configuration of passwords, key, etc.
# Copy to secrets.env and edit
# ___ DO NOT COMMIT 'secrets.env' ___

OTREE_SERVER_URL="http://localhost:8000"

# You can see the next ones to any value you like.
# They are used to authenticate the bot with the oTree server.
# When your oTree server is available in the network 
# it is recommended to use 'real' passwords.
OTREE_ADMIN_PASSWORD=****
OTREE_REST_KEY=****

# This one is required if you plan to use one of OpenAI's Chat-GPT models 
OPENAI_API_KEY=******

# You do not have to set this one for testing
BOT_DB_SQLITE="tests/botex.db"

# --- Everything below is only needed if you use local LLMs ----

# If you have a running llama.cpp server, you can set this to 0 (or False)
# and set the server URL. 
START_LLAMA_SERVER=1
LLAMA_SERVER_URL="http://localhost:8080"

# If you do not have a running llama.cpp server, set the above to 1 (or True).
# In this case, botex will start a llama.cpp server for you.
# For this, you need to set the path to the llama-server executable and the 
# path to the LLM model.
PATH_TO_LLAMA_SERVER="llama.cpp/llama-server"
LOCAL_LLM_PATH="models/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf"

# The below should be 0 if you are GPU poor :(, 
# otherwise, you can set it depending on your GPU memory size, 
# you can also increase the number of slots for more parallelism if 
# you have plenty of GPU memory.
NUMBER_OF_LAYERS_TO_OFFLOAD_TO_GPU=0
NUM_SLOTS=1
